{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PrvPXRrK1yV"
      },
      "source": [
        "# NLP 702 Deep Learning for Natural Language Processing\n",
        "## Finetuning T5 model \n",
        "\n",
        "### Goal of this tutorial:\n",
        "- Know the background of Text-to-Text Transfer Transformer (T5) model.\n",
        "- Learn how to finetune T5 model for sentiment analysis\n",
        "\n",
        "### References\n",
        "Some useful references:\n",
        "1. T5 Original Paper https://arxiv.org/pdf/1910.10683.pdf\n",
        "2. T5 HuggingFace blog https://huggingface.co/transformers/model_doc/t5.html\n",
        "3. T5 model card https://huggingface.co/t5-base \n",
        "4. T5 blog from Google AI https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html (material for T5 background is borrowed from this blog)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1k__iZ8N_44"
      },
      "source": [
        "### T5 model - Background\n",
        "\n",
        "\n",
        "<img src=\"https://1.bp.blogspot.com/-89OY3FjN0N0/XlQl4PEYGsI/AAAAAAAAFW4/knj8HFuo48cUFlwCHuU5feQ7yxfsewcAwCLcBGAsYHQ/s1600/image2.png\" height=\"250\" width=\"550\"/>\n",
        "\n",
        "\n",
        "Text-to-Text Transfer Transformer (T5) model is an encoder-decoder model pretrained to fill in dropped-out spans of text (denoted by \\<M\\>) from documents in a large-scale unlabeled dataset. With T5, all NLP tasks can be reframed into a unified text-to-text format where the input and output are always text strings, in contrast to BERT-style models that can only output either a class label or a span of the input. T5's text-to-text framework allows us to use the same model, loss function, and hyperparameters on any NLP task, including machine translation, document summarization, question answering, and classification tasks (e.g., sentiment analysis). One can even apply T5 to regression tasks by training it to predict the string representation of a number instead of the number itself.\n",
        "\n",
        "<img src=\"https://1.bp.blogspot.com/-o4oiOExxq1s/Xk26XPC3haI/AAAAAAAAFU8/NBlvOWB84L0PTYy9TzZBaLf6fwPGJTR0QCLcBGAsYHQ/s1600/image3.gif\" height=\"250\" width=\"550\"/>\n",
        "\n",
        "In the above illustration, T5 is flexibly finetuned on several (diverse) supervised tasks:\n",
        "- **Machine Translation** - Translate sentence from English to German \n",
        "- **Sentence Acceptability (CoLA)** - Classify if a given sentence is grammatically and syntactically acceptable\n",
        "- **Semantic Textual Similarity (STS)** - Predict how similar two given sentences are (regression task)\n",
        "- **Summarization** - Summarize a given passage\n",
        "\n",
        "### T5 model - Finetuning on sentiment analysis task\n",
        "\n",
        "In this tutorial we will focus on finetuning T5 model on sentiment analysis task. Specifically, we focus on classifying the sentiment of the tweet. We make use of the dataset provided by ``SemEval-2016 Task 4 on Sentiment Analysis on Twitter`` (http://alt.qcri.org/semeval2016/task4/). We focus on the subtask A which is coined as **message polarity classification task**. In this task, given a tweet, we need to predict whether the tweet is of **positive, negative or neutral sentiment**. We have 6,000, 1,999 and 20,632 tweets in train, validation, and test set respectively. We have already preprocessed (tokenization, removing URLs, mentions, hashtags and so on) the tweets and placed it under ``data/sentiment-twitter-2016-task4`` folder in three files as ``train.tsv``, ``dev.tsv`` and ``test.tsv``. Some example tweets include:\n",
        "\n",
        "| class index | class name | tweet example |\n",
        "| ----------------- | ----------- |-------------|\n",
        "| 0  | Negative   | --MENTION-- --MENTION-- the reason i ask is because it may be the manufacturer's fault and they could help you |\n",
        "| 1  | Neutral | just ordered my ever tablet --MENTION-- surface pro --DIGIT-- ssd hopefully it works out for dev to replace my laptop |\n",
        "| 2  | Positive | dear --MENTION-- the newooffice for mac is great and all but no lync update c'mon |\n",
        "\n",
        "This tutorial assumes the data can be found at: `/content/drive/MyDrive/Colab Notebooks/sentiment-twitter-2016-task4`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JprmrJhbK5Xn"
      },
      "source": [
        "#### Install all dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spqTYO5pZXZ2",
        "outputId": "831b4201-fa2d-4797-faa1-5d651d0d6fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.49.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Using cached huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: huggingface-hub\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.0.19\n",
            "    Uninstalling huggingface-hub-0.0.19:\n",
            "      Successfully uninstalled huggingface-hub-0.0.19\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 1.5.0 requires huggingface-hub<0.1.0, but you have huggingface-hub 0.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.12.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (1.5.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Collecting tqdm>=4.62.1\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, tqdm, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.49.0\n",
            "    Uninstalling tqdm-4.49.0:\n",
            "      Successfully uninstalled tqdm-4.49.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 1.5.0\n",
            "    Uninstalling datasets-1.5.0:\n",
            "      Successfully uninstalled datasets-1.5.0\n",
            "Successfully installed datasets-2.9.0 responses-0.18.0 tqdm-4.64.1 urllib3-1.26.14\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.8/dist-packages (2.3.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (4.9.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (0.8.10)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (1.21.6)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (2.7.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (0.4.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install sacrebleu\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XWzJSPqZmGx"
      },
      "source": [
        "#### HuggingFace's run_seq2seq.py\n",
        "\n",
        "We will use T5 implementation provided by HuggingFace to finetune T5 for sentiment analysis. \n",
        "\n",
        "The **run_seq2seq.py** code provides implementation for fine-tuning T5 model and evaluating a trained T5 checkpoint. This tutorial assumes the code can be found at this path: `/content/run_seq2seq.py`.\n",
        "\n",
        "Let's inspect some of the arguments the code takes in:\n",
        "- **task** - Name of the task. Set it to `translation_en_to_en`, as it doesn't matter for text classification. You design your own task prefix (or prompt) for you task by using the input argument `source_prefix`.\n",
        "- **train_file** - Path to the training data file. The code accepts two format: jsonlines and csv. We will convert our sentiment dataset into jsonlines format.\n",
        "- **validation_file** - Path to the validation data file. The code accepts two format: jsonlines and csv. We will convert our sentiment dataset into jsonlines format.\n",
        "- **test_file** - Path to the test data file. The code accepts two format: jsonlines and csv. We will convert our sentiment dataset into jsonlines format.\n",
        "- **text_column** - Name of the column in the jsonlines dataset that corresponds to the input text (which is tweet in our setting). We will set it to \"input_text\".\n",
        "- **summary_column** - Name of the column in the jsonlines dataset that corresponds to the target text (which is sentiment label in our setting). We will set it to \"target_text\".\n",
        "- **model_name_or_path** - Model's shortcut name or path to pretrained model. For fine-tuning, we will set it to \"t5-base\". For evaluation, we will set it to path to the saved checkpoint.\n",
        "- **do_train** - Whether to run training or not. Set it during training.\n",
        "- **num_train_epochs** - Total number of training epochs to perform\n",
        "- **output_dir** - Output directory where the model predictions and checkpoints will be written.\n",
        "- **save_steps** - Number of updates steps before two checkpoint saves (default: 500)\n",
        "- **save_total_limit** - If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in **output_dir**\n",
        "- **predict_with_generate**, **do_predict** - Whether to generate the target text (sentiment label for our case) for validation and test or not.\n",
        "\n",
        "For extensive set of training arguments (e.g., learning rate, maximum steps, batch size), look [here](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9Y7McL8ozSo"
      },
      "source": [
        "\n",
        "\n",
        "#### Convert the dataset to jsonlines\n",
        "\n",
        "Our original sentiment data is in tsv format. For example, the first training sample in the dataset:\n",
        "\n",
        "dear \\<<\\<MENTION>>> the newooffice for mac is great and all but no lync update c'mon \\<TAB-SPACE>  1\n",
        "\n",
        "We can convert the sample to jsonlines format:\n",
        "\n",
        "{\"input_text\": \"dear <<<MENTION>>> the newooffice for mac is great and all but no lync update c'mon\", \"target_text\": \"positive\"}\n",
        "\n",
        "Note that the **input_text** field contains the original tweet (that corresponds to the value we use to set **text_column**) and the **target_text** field contains the sentiment label (that corresponds to the value we use to set **summary_column**).\n",
        "\n",
        "Let's convert the original dataset to jsonlines format now:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJ-E7tFsyppc"
      },
      "outputs": [],
      "source": [
        "import os, json\n",
        "\n",
        "def convert_sentiment_dataset_to_text2text_format(original_folder, destination_folder):\n",
        "    # check if jsonlines directtory doesn't exist\n",
        "    if not os.path.exists(destination_folder):\n",
        "        os.makedirs(destination_folder)\n",
        "    for src_file in [\"train.tsv\", \"dev.tsv\", \"test.tsv\"]:\n",
        "        t5_file = open(destination_folder + \"/\" + src_file.split(\".\")[0] + \".json\", \"w\")\n",
        "        for line in open(original_folder + \"/\" + src_file):\n",
        "            # read tsv line\n",
        "            tweet, sentiment = line.strip().split(\"\\t\")\n",
        "            # prepare json\n",
        "            t5_out = {}\n",
        "            t5_out[\"input_text\"] = tweet\n",
        "            if sentiment == \"0\":\n",
        "                t5_out[\"target_text\"] = \"negative\"\n",
        "            elif sentiment == \"1\":\n",
        "                t5_out[\"target_text\"] = \"neutral\"\n",
        "            else:\n",
        "                t5_out[\"target_text\"] = \"positive\"\n",
        "            # write json\n",
        "            t5_file.write(json.dumps(t5_out))\n",
        "            t5_file.write(\"\\n\")\n",
        "      \n",
        "        t5_file.close()\n",
        "\n",
        "# assumes \"/content/sentiment-twitter-2016-task4\" contains original data\n",
        "# assumes \"/content/text2text-sentiment\" contains jsonlines data\n",
        "convert_sentiment_dataset_to_text2text_format(\"/content/sentiment-twitter-2016-task4\", \"text2text-sentiment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let take a look at the first example:"
      ],
      "metadata": {
        "id": "LxM_oiLPa7Oz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = [json.loads(x.replace(\"\\n\", \"\")) for x in open(\"/content/text2text-sentiment/train.json\").readlines()]"
      ],
      "metadata": {
        "id": "6r1yfg9mZs3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb8XSPROad6c",
        "outputId": "25c2c9ab-2e9f-4f1b-fdde-4bfb0926cbfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_text': \"dear <<<MENTION>>> the newooffice for mac is great and all but no lync update c'mon\",\n",
              " 'target_text': 'positive'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the dataloader, the prefix will be add in front of the input text. See Line 449 in `run_seq2seq.py`. In this example, the prefix is the task name (`translation_en_to_en`). The input of T5 will be `translation_en_to_en: \"dear <<<MENTION>>> the newooffice....`\n",
        "\n"
      ],
      "metadata": {
        "id": "f7pE5AHPc75w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsytS7o-p7QM"
      },
      "source": [
        "\n",
        "#### Fine-tuning T5 model\n",
        "\n",
        "That's all the preparation needed. We can now use **run_seq2seq.py** script to finetune T5 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6t_HoP5Kqsa"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/sentiment-ckpts # ensure the directory to store the checkpoints is empty\n",
        "!python \"/content/run_seq2seq.py\" \\\n",
        "        --task translation_en_to_en \\\n",
        "        --text_column input_text \\\n",
        "        --summary_column target_text \\\n",
        "        --train_file /content/text2text-sentiment/train.json \\\n",
        "        --validation_file /content/text2text-sentiment/dev.json \\\n",
        "        --do_predict \\\n",
        "        --predict_with_generate \\\n",
        "        --test_file /content/text2text-sentiment/test.json \\\n",
        "        --save_total_limit 5 \\\n",
        "        --num_train_epochs 3 \\\n",
        "        --output_dir /content/sentiment-ckpts \\\n",
        "        --model_name_or_path t5-base \\\n",
        "        --do_train \\\n",
        "        --do_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKdocsdaqVkX"
      },
      "source": [
        "The above run saves a checkpoint every **save_steps** steps (default 500) and keeps only the latest **save_total_limit** checkpoints. The run doesn't print the validation performance so it's harder to monitor the training process. One trick is to save checkpoints frequently (within the hard disk space) and evaluate each checkpoint post training.\n",
        "\n",
        "#### Evaluating T5 model checkpoint\n",
        "\n",
        "Let's evaluate the latest checkpoints. We will use f1-micro as the metric to evaluate the quality of the classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OH0PeJoMN2da"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def evaluate_checkpoint(prediction_dir, data_dir, metric=\"f1_micro\", do_val=True, do_test=True):\n",
        "  # compute validation performance\n",
        "    if do_val:\n",
        "        # read gold labels\n",
        "        gold_labels = []\n",
        "        for line in open(data_dir + \"/dev.json\"):\n",
        "            gold_labels.append(json.loads(line.strip())[\"target_text\"])\n",
        "        # read predicted labels\n",
        "        pred_labels = []\n",
        "        for line in open(prediction_dir + \"_val_preds_seq2seq.txt\"):\n",
        "            pred_labels.append(line.strip())\n",
        "        # compute metric\n",
        "        if metric == \"f1_micro\":\n",
        "            print(\"%s validation F1-micro: %.2f\"%(prediction_dir.split(\"/\")[-1], f1_score(gold_labels, pred_labels, average=\"micro\")))\n",
        "\n",
        "  # compute test performance\n",
        "    if do_test:\n",
        "        # read gold labels\n",
        "        gold_labels = []\n",
        "        for line in open(data_dir + \"/test.json\"):\n",
        "            gold_labels.append(json.loads(line.strip())[\"target_text\"])\n",
        "        # read predicted labels\n",
        "        pred_labels = []\n",
        "        for line in open(prediction_dir + \"_test_preds_seq2seq.txt\"):\n",
        "            pred_labels.append(line.strip())\n",
        "        # compute metric\n",
        "        if metric == \"f1_micro\":\n",
        "            print(\"%s test F1-micro: %.2f\"%(prediction_dir.split(\"/\")[-1], f1_score(gold_labels, pred_labels, average=\"micro\")))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjXhdo1-zFUK"
      },
      "source": [
        "Let's compute the validation and the testing performance of the checkpoint saved after 500th step: `/content/sentiment-ckpts/checkpoint-500`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIaMDw70zFdJ"
      },
      "outputs": [],
      "source": [
        "!python \"/content/run_seq2seq.py\" \\\n",
        "        --model_name_or_path /content/sentiment-ckpts/checkpoint-500 \\\n",
        "        --task translation_en_to_en \\\n",
        "        --text_column input_text \\\n",
        "        --summary_column target_text \\\n",
        "        --train_file /content/text2text-sentiment/train.json \\\n",
        "        --validation_file /content/text2text-sentiment/dev.json \\\n",
        "        --test_file /content/text2text-sentiment/test.json \\\n",
        "        --do_predict \\\n",
        "        --predict_with_generate \\\n",
        "        --output_dir /content/sentiment-ckpts \\\n",
        "        --do_eval\n",
        "\n",
        "evaluate_checkpoint(\"/content/sentiment-ckpts/checkpoint-500\", \n",
        "                    \"/content/text2text-sentiment\", metric=\"f1_micro\", \n",
        "                    do_val=True, do_test=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EMyMldXss-y"
      },
      "source": [
        "Let's compute the validation and the testing performance of the checkpoint saved after 2,000th step: `/content/sentiment-ckpts/checkpoint-2000`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDPlKDzSstD3"
      },
      "outputs": [],
      "source": [
        "!python \"/content/run_seq2seq.py\" \\\n",
        "        --model_name_or_path /content/sentiment-ckpts/checkpoint-2000 \\\n",
        "        --task translation_en_to_en \\\n",
        "        --text_column input_text \\\n",
        "        --summary_column target_text \\\n",
        "        --train_file /content/text2text-sentiment/train.json \\\n",
        "        --validation_file /content/text2text-sentiment/dev.json \\\n",
        "        --test_file /content/text2text-sentiment/test.json \\\n",
        "        --do_predict --predict_with_generate \\\n",
        "        --output_dir /content/sentiment-ckpts \\\n",
        "        --do_eval\n",
        "        \n",
        "evaluate_checkpoint(\"/content/sentiment-ckpts/checkpoint-2000\", \"/content/text2text-sentiment\", metric=\"f1_micro\", do_val=True, do_test=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYyR7oIfstKM"
      },
      "source": [
        "Let's compute the validation and the testing performance of the final (best) checkpoint: `/content/sentiment-ckpts`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uj_70zp6stPV"
      },
      "outputs": [],
      "source": [
        "!python \"/content/run_seq2seq.py\" \\\n",
        "        --model_name_or_path /content/sentiment-ckpts \\\n",
        "        --task translation_en_to_en \\\n",
        "        --text_column input_text \\\n",
        "        --summary_column target_text \\\n",
        "        --train_file /content/text2text-sentiment/train.json \\\n",
        "        --validation_file /content/text2text-sentiment/dev.json \\\n",
        "        --test_file /content/text2text-sentiment/test.json \\\n",
        "        --do_predict \\\n",
        "        --predict_with_generate \\\n",
        "        --output_dir /content/sentiment-ckpts \\\n",
        "        --do_eval\n",
        "\n",
        "evaluate_checkpoint(\"/content/sentiment-ckpts/t5-base\", \"/content/text2text-sentiment\", \n",
        "                    metric=\"f1_micro\", do_val=True, do_test=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3gp6WeoYbtR"
      },
      "source": [
        "That's it!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}