{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a79cb19b",
   "metadata": {},
   "source": [
    "# This is a tutorial for machine translation with T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "820aaa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a11fcbc",
   "metadata": {},
   "source": [
    "## We will use pretrained t5-small model to finetune a English to French model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7e3e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:164: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#load tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ff8b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will use bleu score as the evaluation metric\n",
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdafa3a8",
   "metadata": {},
   "source": [
    "## First we need to read the files and convert it into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d996903",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "with open('eng-fra.txt',encoding='UTF-8') as my_file:\n",
    "    Lines = my_file.readlines()\n",
    "    for line in Lines:\n",
    "        strs=line.strip().split(\"\t\", 1)\n",
    "        lst.append([strs[0],strs[1]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b227ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lst,columns =['eng','fra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "847d25d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Ça alors !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>Au feu !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135837</th>\n",
       "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
       "      <td>Une empreinte carbone est la somme de pollutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135838</th>\n",
       "      <td>Death is something that we're often discourage...</td>\n",
       "      <td>La mort est une chose qu'on nous décourage sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135839</th>\n",
       "      <td>Since there are usually multiple websites on a...</td>\n",
       "      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135840</th>\n",
       "      <td>If someone who doesn't know your background sa...</td>\n",
       "      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135841</th>\n",
       "      <td>It may be impossible to get a completely error...</td>\n",
       "      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135842 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "0                                                     Go.   \n",
       "1                                                    Run!   \n",
       "2                                                    Run!   \n",
       "3                                                    Wow!   \n",
       "4                                                   Fire!   \n",
       "...                                                   ...   \n",
       "135837  A carbon footprint is the amount of carbon dio...   \n",
       "135838  Death is something that we're often discourage...   \n",
       "135839  Since there are usually multiple websites on a...   \n",
       "135840  If someone who doesn't know your background sa...   \n",
       "135841  It may be impossible to get a completely error...   \n",
       "\n",
       "                                                      fra  \n",
       "0                                                    Va !  \n",
       "1                                                 Cours !  \n",
       "2                                                Courez !  \n",
       "3                                              Ça alors !  \n",
       "4                                                Au feu !  \n",
       "...                                                   ...  \n",
       "135837  Une empreinte carbone est la somme de pollutio...  \n",
       "135838  La mort est une chose qu'on nous décourage sou...  \n",
       "135839  Puisqu'il y a de multiples sites web sur chaqu...  \n",
       "135840  Si quelqu'un qui ne connaît pas vos antécédent...  \n",
       "135841  Il est peut-être impossible d'obtenir un Corpu...  \n",
       "\n",
       "[135842 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "396f9d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a customized dataset class\n",
    "class CustomDataset():\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.eng = list(dataframe['eng'])\n",
    "        self.fra = list(dataframe['fra'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eng)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #we need to get the input ids of input(English) and output(French)\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            self.eng[index],\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "        outputs = self.tokenizer.encode_plus(\n",
    "            self.fra[index],\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        labels=outputs['input_ids']   \n",
    "        return torch.tensor(input_ids, dtype=torch.long),torch.tensor(attention_mask, dtype=torch.long),torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5eb5ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split and create dataloders\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.5,random_state=12345)\n",
    "\n",
    "train_set = CustomDataset(train, tokenizer)\n",
    "trainloader = DataLoader(train_set, batch_size=2,shuffle=True)\n",
    "#we only randomly pick 2000 samples as test_set\n",
    "test_set = CustomDataset(test[:2000], tokenizer)\n",
    "testloader = DataLoader(test_set, batch_size=2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "278e0552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground truth of test_set\n",
    "true_list=test[:2000]['fra'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41868202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train_loader, model,optimizer):\n",
    "    \"\"\"one epoch training\"\"\"\n",
    "\n",
    "\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    for idx, (input_ids,attention_mask,labels) in enumerate(train_loader):\n",
    "\n",
    "\n",
    "        # replace padding token id's of the labels by -100 so it's ignored by the loss\n",
    "        labels[labels==0]=-100\n",
    "        if torch.cuda.is_available():\n",
    "            input_ids = input_ids.cuda()\n",
    "            attention_mask = attention_mask.cuda()\n",
    "            labels= labels.cuda()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        #calculate the loss \n",
    "        loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels).loss\n",
    "        \n",
    "        #accumulate the loss\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "\n",
    "\n",
    "        # SGD\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return epoch_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78cd0e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating(eval_loader, model,optimizer):\n",
    "    epoch_loss = 0\n",
    "    pred_list=[]\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for idx, (input_ids,attention_mask,labels) in enumerate(eval_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                input_ids = input_ids.cuda()\n",
    "                attention_mask = attention_mask.cuda()\n",
    "            \n",
    "            \n",
    "            #get the output sequence\n",
    "            output_sequences = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "            )\n",
    "            outputs=tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n",
    "            for samples in outputs:\n",
    "                pred_list.append(samples)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #calculate bleu score\n",
    "    bleu_score=bleu.compute(predictions=pred_list, references=true_list)    \n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "432bebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "#Set the optimizer and learning rate is recommended to be 1e-4 by huggingface\n",
    "optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=1e-4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e863c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "for i in range(5):\n",
    "\n",
    "\n",
    "    print('epochs:'+ str(i+1))\n",
    "    \n",
    "    #training\n",
    "    tr_loss=training(trainloader, model,optimizer)\n",
    "    print('training_loss:'+str(round(tr_loss, 5)))\n",
    "\n",
    "    #evaluating\n",
    "    bleu_score=evaluating(testloader, model,optimizer)\n",
    "    print('bleu_score:'+str(round(bleu_score['bleu'], 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61139aa",
   "metadata": {},
   "source": [
    "## Due to the large amount of training data. The training is done on a cluster.\n",
    "we can run evaluating function again to check the bleu score after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9387220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_score=evaluating(testloader, model,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1500aa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.4875162591403384,\n",
       " 'precisions': [0.7436706689536878,\n",
       "  0.5589662027833002,\n",
       "  0.4481323877068558,\n",
       "  0.3667598416026089],\n",
       " 'brevity_penalty': 0.9535654925674059,\n",
       " 'length_ratio': 0.9546109510086456,\n",
       " 'translation_length': 14575,\n",
       " 'reference_length': 15268}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543e4f18",
   "metadata": {},
   "source": [
    "## a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e34008fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HuggingFace est une société.', 'Bienvenue à NYC.']\n"
     ]
    }
   ],
   "source": [
    "#Check the model outputs after training\n",
    "sentences = [\"HuggingFace is a company.\", \"Welcome to NYC.\"]\n",
    "inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True)\n",
    "output_sequences = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    ")\n",
    "print(tokenizer.batch_decode(output_sequences, skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "508013c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.5969491792019646,\n",
       " 'precisions': [0.8888888888888888,\n",
       "  0.7142857142857143,\n",
       "  0.6,\n",
       "  0.3333333333333333],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.0,\n",
       " 'translation_length': 9,\n",
       " 'reference_length': 9}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.compute(predictions=['HuggingFace est une société.', 'Bienvenue à NYC.'], references=[\"HuggingFace est une entreprise.\", \"Bienvenue à NYC.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf6c7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
