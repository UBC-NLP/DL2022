{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqDvmzPtY3j_"
      },
      "source": [
        "# Transformer model - Machine Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDsWzitHZO3x"
      },
      "source": [
        "### Tutorial Topics\n",
        "- Transformer model\n",
        "\n",
        "### Software Requirements\n",
        "This notebook was last tested on:\n",
        "- Python (3.7)\n",
        "- PyTorch (1.7.1) \n",
        "- torchtext (0.5.0)\n",
        "- NLTK (3.5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.7.1 torchtext==0.5.0 nltk==3.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyofV03dW5NZ",
        "outputId": "4cc08910-bcf4-4c61-c628-bf8c79697ad8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.7.1 in /usr/local/lib/python3.8/dist-packages (1.7.1)\n",
            "Requirement already satisfied: torchtext==0.5.0 in /usr/local/lib/python3.8/dist-packages (0.5.0)\n",
            "Requirement already satisfied: nltk==3.5 in /usr/local/lib/python3.8/dist-packages (3.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.7.1) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.7.1) (1.21.6)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (from torchtext==0.5.0) (0.1.97)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from torchtext==0.5.0) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.5.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.5.0) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from nltk==3.5) (2022.6.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.5.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.5.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.5.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.5.0) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJtlswApZQyd",
        "outputId": "ba062680-c315-4bf5-8867-7a3eac293087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UKNfK-PvESg"
      },
      "source": [
        "## Seq2Seq model with attention - Recap\n",
        "\n",
        "One inherent issue with recurrent neural network is that RNNs are **sequential in nature**, that is, each hidden state depends on the output of the previous hidden state. This issue prevents RNN from parallelization within training examples, which especially becomes critical for modeling longer sequences (e.g. documents). \n",
        "\n",
        "![](https://drive.google.com/uc?id=1scvvOneIAFk5Sob1SdghccJBy8qq9ePU)\n",
        "\n",
        "\n",
        "## Transformer model\n",
        "\n",
        "[Vaswani et al., 2017](https://arxiv.org/pdf/1706.03762.pdf) propose the Transformer, a model architecture that throws away recurrence and relies entirely on attention mechanism to draw global dependencies between input and output. The Transfomer allows for significantly more parallelization and has been used to build the current state-of-the-art models for several NLP (also Speech, Vision) applications, including:\n",
        "- machine translation (focus of this tutorial)\n",
        "- sentiment analysis, question answering, natural language inference (e.g., [BERT](https://arxiv.org/abs/1810.04805))\n",
        "- story generation, news article generation (e.g., [GPT-2](https://en.wikipedia.org/wiki/GPT-2))\n",
        "- and many more\n",
        "\n",
        "![](https://nlp.seas.harvard.edu/images/the-annotated-transformer_14_0.png)\n",
        "\n",
        "Picture Courtesy: https://nlp.seas.harvard.edu/images/the-annotated-transformer_14_0.png\n",
        "\n",
        "In this tutorial, we will look at core components of Transformer model and train a Transformer model from scratch to translate French sentence to English sentence.\n",
        "\n",
        "The sections which are taken from the previous tutorial include:\n",
        "* Preparing Data\n",
        "* Train logic (most parts)\n",
        "* Evaluation logic (most parts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7vLl5mFKCgO"
      },
      "source": [
        "## Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n76MDk3BZSPI",
        "outputId": "ac7e5aee-c873-413c-8853-89ee8536d71b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import math, copy, time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn\n",
        "seaborn.set_context(context=\"talk\")\n",
        "%matplotlib inline\n",
        "\n",
        "# set the pseudo-random generator\n",
        "manual_seed = 77\n",
        "torch.manual_seed(manual_seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "n_gpu = torch.cuda.device_count()\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed(manual_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEM1Ah413yPC"
      },
      "source": [
        "### Preparing Data\n",
        "\n",
        "***Define tokenizers:***\n",
        "we create the tokenizers. A tokenizer is used to turn a string containing a sentence into a list of individual tokens that make up that string.\n",
        "\n",
        "spaCy has model for each language (\"fr\" for French and \"en\" for English) which need to be loaded so we can access the tokenizer of each model.\n",
        "\n",
        "***Note***: the models must first be downloaded using the following on the command line:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgAzBFPa34OA",
        "outputId": "5de99f85-fc36-4792-c9b3-ac9393fc6da4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 111.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-sm==3.4.1) (3.4.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (6.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.21.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (57.4.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.11.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fr-core-news-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.4.0/fr_core_news_sm-3.4.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.3 MB 14.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from fr-core-news-sm==3.4.0) (3.4.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (6.3.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (8.1.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.10.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.0.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.4.5)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (4.4.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2022.12.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->fr-core-news-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download fr_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w7Vo9aLW4JJI"
      },
      "outputs": [],
      "source": [
        "import fr_core_news_sm\n",
        "import en_core_web_sm\n",
        "\n",
        "spacy_fr = fr_core_news_sm.load()\n",
        "spacy_en = en_core_web_sm.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7MRaUm64Mn6"
      },
      "source": [
        "Next, we create the tokenizer functions. These can be passed to TorchText and will take in the sentence as a string and return the sentence as a list of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YenFu4bl4PpT"
      },
      "outputs": [],
      "source": [
        "def tokenize_fr(text):\n",
        "    \"\"\"\n",
        "    Tokenizes French text from a string into a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_fr.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bajlvdbS4SM8"
      },
      "source": [
        "`TorchText`'s Fields handle how data should be processed. You can read all of the possible arguments [here](https://github.com/pytorch/text/blob/master/torchtext/data/field.py#L61).\n",
        "\n",
        "We set the tokenize argument to the corresponding tokenization function for each, with French being the `SRC` (source) field and English being the `TRG` (target) field. The field also appends the \"start of sequence\" (\\<sos\\>) and \"end of sequence\" (\\<eos\\>) tokens via the `init_token` and `eos_token` arguments, and converts all words to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IljSJYO34U1R"
      },
      "outputs": [],
      "source": [
        "SRC = data.Field(tokenize = tokenize_fr, \n",
        "            # init_token = '<sos>', # since initial encoder hidden state is always set to zero, the network can figure out that the time step is 0 and this token is optional\n",
        "            eos_token = '<eos>', \n",
        "            lower = True)\n",
        "TRG = data.Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV-Fmhgt4XQ8"
      },
      "source": [
        "Next, we load the train, validation and test data.\n",
        "\n",
        "The dataset we'll be using is the [Multi30k](https://github.com/multi30k/dataset) dataset. This is a dataset with ~30,000 parallel English, French and German sentences. You can find more information in [WMT18](http://www.statmt.org/wmt18/multimodal-task.html). This corpus was officially split to Training (29,000 sentences), Validation (1,014 sentences), and multiple Test sets. We provide Test 2016 (1,000 sentences). \n",
        "\n",
        "The raw dataset is extracted to three `.tsv` files. Each file includes two column, 'English' and 'French'. We use `torchtext.data.TabularDataset` to load these tsv files. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "X4Sdsehn4a12"
      },
      "outputs": [],
      "source": [
        "train, val, test = data.TabularDataset.splits(\n",
        "    path='./drive/MyDrive/Colab_Notebooks/eng-fre/', train='train_eng_fre.tsv',validation='val_eng_fre.tsv', test='test_eng_fre.tsv', \n",
        "    format='tsv', skip_header=True, fields=[('TRG', TRG), ('SRC', SRC)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9p0puCR4e9a"
      },
      "source": [
        "We can double check that we've loaded the right number of examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW20Vuu04gtG",
        "outputId": "e680d0b4-2a1a-4530-ba52-ab4c6877c662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 29000\n",
            "Number of validation examples: 1014\n",
            "Number of testing examples: 1000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of training examples: {len(train.examples)}\")\n",
        "print(f\"Number of validation examples: {len(val.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test.examples)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIgiKHjM4lru"
      },
      "source": [
        "We can also print out an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwaIIrt-4oB6",
        "outputId": "a4657901-609d-4570-cac1-66b0bb0d6936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'TRG': ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.'], 'SRC': ['deux', 'jeunes', 'hommes', 'blancs', 'sont', 'dehors', 'près', 'de', 'buissons', '.']}\n"
          ]
        }
      ],
      "source": [
        "print(vars(train.examples[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1eTer8o4qTu",
        "outputId": "52b1828a-22ee-433e-b5d0-ce97795ad621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'TRG': ['an', 'older', ',', 'overweight', 'man', 'flips', 'a', 'pancake', 'while', 'making', 'breakfast', '.'], 'SRC': ['un', 'homme', 'âgé', 'en', 'surpoids', 'fait', 'sauter', 'une', 'crêpe', 'en', 'préparant', 'le', 'petit', 'déjeuner', '.']}\n"
          ]
        }
      ],
      "source": [
        "print(vars(val.examples[100]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w_Ziwfv4tV2"
      },
      "source": [
        "Next, we'll build the vocabulary for the source and target languages. \n",
        "\n",
        "The vocabulary is used to associate each unique token with an index and this is used to build a one-hot encoding for each token. The vocabularies of the source and target languages have some minimal overlap.\n",
        "\n",
        "Using the `min_freq` argument, we only allow tokens that appear at least 2 times to appear in our vocabulary. Tokens that appear only once are converted into an `<unk>` (unknown) token.\n",
        "\n",
        "It is important to note that your vocabulary should only be built from the `training set` and not the `validation/test set`. This prevents **\"information leakage\"** into your model, giving you artifically inflated validation/test scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "59r6mL7J4y4a"
      },
      "outputs": [],
      "source": [
        "TRG.build_vocab(train,min_freq=2)\n",
        "SRC.build_vocab(train,min_freq=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z49Fmd4342ei",
        "outputId": "ad65e0f0-3510-45b0-9ca9-3b794643485c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in source (fr) vocabulary: 6469\n",
            "Unique tokens in target (en) vocabulary: 5893\n"
          ]
        }
      ],
      "source": [
        "print(f\"Unique tokens in source (fr) vocabulary: {len(SRC.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph-VDsasu-12"
      },
      "source": [
        "`TRG.vocab.stoi` is the dictionary of word to index. For example, the index of `<pad>` is 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCNG_y5Hu2Qz",
        "outputId": "74c708f4-584d-4654-ce8b-f1ec04eb2673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "print(TRG.vocab.stoi['<pad>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP2tGhlB4_N6"
      },
      "source": [
        "The final step of preparing the data is to create the `iterators` to generate batches. These can be iterated on to return a batch of data. The text of both source and target text will be converted to two sequence of corresponding indexes, using the vocabularies.\n",
        "\n",
        "\n",
        "We also need to define a `torch.device`. This indicate whether the input `tensors` should be sent to `GPU` or not. We already defined the `device` variable before. \n",
        "\n",
        "Finally, the output of the iterator will be `padded`. \n",
        "\n",
        "We use a `BucketIterator` to creates batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnxNOrTPvE7O",
        "outputId": "6eeeeb71-45cc-44d2-bee2-865af98eb0c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CdgS6bBEvK1d"
      },
      "outputs": [],
      "source": [
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train, val, test), # we pass in the datasets we want the iterator to draw data from\n",
        "    batch_sizes=(16, 256, 256),device = device,\n",
        "    sort_key=lambda x: len(x.SRC), # the BucketIterator needs to be told what function it should use to group the data.\n",
        "    sort_within_batch=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFif-pZOvQhx"
      },
      "source": [
        "Each batch will include two tensors: tensor of source language and tensor of target language. The size of each tensor is **[max_length, batch_size]**. Each example is already padded within batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzicRD44vNSv",
        "outputId": "5c3ed16b-9c49-4fae-dbf4-6aa8f0a70c39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor size of source language: torch.Size([25, 16])\n",
            "tensor size of target language: torch.Size([23, 16])\n",
            "the tensor of first example in target language: tensor([  2,   4,  34, 759,   8,   4, 308, 363,   5,   3,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# batch example of training data\n",
        "for batch in train_iter:\n",
        "    src = batch.SRC\n",
        "    trg = batch.TRG\n",
        "    print('tensor size of source language:', src.shape)\n",
        "    print('tensor size of target language:', trg.shape)\n",
        "    print('the tensor of first example in target language:', trg[:,0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd-1h9chxSzo"
      },
      "source": [
        "We save our Fields for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./drive/MyDrive/Colab_Notebooks/ckpt_attn/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL04jjX1ZZYT",
        "outputId": "83d3b7a6-b962-43ee-a108-6c7f32b78c58"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘./drive/MyDrive/Colab_Notebooks/ckpt_attn/’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Hoe5kPCfxWi4"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"./drive/MyDrive/Colab_Notebooks/ckpt_attn/TRG.Field\",\"wb\")as f:\n",
        "     pickle.dump(TRG,f)\n",
        "\n",
        "with open(\"./drive/MyDrive/Colab_Notebooks/ckpt_attn/SRC.Field\",\"wb\")as f:\n",
        "     pickle.dump(SRC,f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trP7PWt94fPw"
      },
      "source": [
        "### Transformer - Quick Theory with sample code\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1nis5Pu3GDOUU4608i1qAzs-tRjVSk18L)\n",
        "\n",
        "Picture Courtesy: [Tay et al., 2020](https://arxiv.org/pdf/2009.06732.pdf)\n",
        "\n",
        "We borrow the following theory on Transformers from [Tay et al., 2020](https://arxiv.org/pdf/2009.06732.pdf).\n",
        "\n",
        "Transformer blocks consist of \n",
        "- Multi-head self-attention mechanism (red block)\n",
        "- Position-wise feed-forward network (blue block)\n",
        "- Layer normalization (green block)\n",
        "- Residual connection (black arrows from mult-head self attention input to layer normalization and arrows from feed forward input to layer normalization\n",
        "\n",
        "The input to the Transformer model is often a tensor of shape $\\mathbb{R}^B \\times \\mathbb{R}^N$ (similar to RNN/LSTM), where B is the batch size and N is the sequence length.\n",
        "\n",
        "The input first passes through an embedding layer (nn.Embedding(vocab_size, $d_{model}$)) that converts each token representation into a $d$ dimensional embedding, i.e., $\\mathbb{R}^B \\times \\mathbb{R}^N \\times \\mathbb{R}^{d_{model}}$.  The new tensor is then additively composed with positional encodings, and passed through a multi-headed self-attention module. Positional encodings can take the form of a sinusoidal input (as in the original transformers) or be trainable embeddings (we'll use this in the tutorial and implement using nn.Embedding(max_seq_len, $d_{model}$)).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p4DM35e8ZcW"
      },
      "source": [
        "#### Positional encodings\n",
        "\n",
        "**Positional encodings** have the same dimension ${d_{model}}$ as the embeddings, so two can be summed: \n",
        "\n",
        "$$PE(pos,2_i) = sin(pos/10000^{2i/{d_{model}}} )$$\n",
        "$$PE(pos,2_i+1) = cos(pos/10000^{2i/{d_{model}}} )$$\n",
        "\n",
        "where $pos$ is the position and $i$ is the dimension.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8na7qE758ZcW"
      },
      "source": [
        "Some sample code for creating a positional encoding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WEDT84n8ZcX",
        "outputId": "7d99ccf0-b347-48a4-b90d-337e6d7d66d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positional encoding of a sample input tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
            "        [ 8.4147e-01,  9.2180e-01,  2.5116e-02,  9.9995e-01,  6.3096e-04,\n",
            "          1.0000e+00,  1.5849e-05,  1.0000e+00,  3.9811e-07,  1.0000e+00],\n",
            "        [ 9.0930e-01,  6.9942e-01,  5.0217e-02,  9.9980e-01,  1.2619e-03,\n",
            "          1.0000e+00,  3.1698e-05,  1.0000e+00,  7.9621e-07,  1.0000e+00],\n",
            "        [ 1.4112e-01,  3.6764e-01,  7.5285e-02,  9.9955e-01,  1.8929e-03,\n",
            "          1.0000e+00,  4.7547e-05,  1.0000e+00,  1.1943e-06,  1.0000e+00],\n",
            "        [-7.5680e-01, -2.1631e-02,  1.0031e-01,  9.9920e-01,  2.5238e-03,\n",
            "          1.0000e+00,  6.3396e-05,  1.0000e+00,  1.5924e-06,  1.0000e+00],\n",
            "        [-9.5892e-01, -4.0752e-01,  1.2526e-01,  9.9875e-01,  3.1548e-03,\n",
            "          1.0000e+00,  7.9245e-05,  1.0000e+00,  1.9905e-06,  1.0000e+00],\n",
            "        [-2.7942e-01, -7.2968e-01,  1.5014e-01,  9.9820e-01,  3.7857e-03,\n",
            "          1.0000e+00,  9.5094e-05,  1.0000e+00,  2.3886e-06,  1.0000e+00],\n",
            "        [ 6.5699e-01, -9.3770e-01,  1.7493e-01,  9.9755e-01,  4.4167e-03,\n",
            "          1.0000e+00,  1.1094e-04,  1.0000e+00,  2.7868e-06,  1.0000e+00],\n",
            "        [ 9.8936e-01, -9.9906e-01,  1.9960e-01,  9.9680e-01,  5.0476e-03,\n",
            "          1.0000e+00,  1.2679e-04,  1.0000e+00,  3.1849e-06,  1.0000e+00],\n",
            "        [ 4.1212e-01, -9.0417e-01,  2.2415e-01,  9.9595e-01,  5.6786e-03,\n",
            "          1.0000e+00,  1.4264e-04,  1.0000e+00,  3.5830e-06,  1.0000e+00]])\n"
          ]
        }
      ],
      "source": [
        "max_seq_len = 10 # maximum sequence length of the input\n",
        "d_model = 10 # size of the token embedding, that is, D\n",
        "\n",
        "# a tensor that stores the positional encoding\n",
        "pe = torch.zeros(max_seq_len, d_model)\n",
        "\n",
        "# compute the positional encoding\n",
        "for pos in range(max_seq_len):\n",
        "    for i in range(0,d_model,2):\n",
        "        pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
        "        pe[pos, i+1] = math.cos(pos / (10000 ** ((2 * i+1)/d_model)))\n",
        "\n",
        "print(\"Positional encoding of a sample input\", pe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-m7pLBDHwiP"
      },
      "source": [
        "Let's print positional encoding for the third token in the sample input:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no_Hn5278ZcY",
        "outputId": "21d77dbb-bf68-4d7f-dd20-54caae5c12d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positional encoding for w in position 3:  tensor([9.0930e-01, 6.9942e-01, 5.0217e-02, 9.9980e-01, 1.2619e-03, 1.0000e+00,\n",
            "        3.1698e-05, 1.0000e+00, 7.9621e-07, 1.0000e+00])\n"
          ]
        }
      ],
      "source": [
        "print(\"Positional encoding for w in position 3: \", pe[2,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1TOmXxF8ZcY"
      },
      "source": [
        "We assume our embedding vector for the third token is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SESHbp88ZcY",
        "outputId": "024a02c8-601d-4c7f-e56d-4d76ed88431e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word embedding for w in position 3 tensor([0.2919, 0.2857, 0.4021, 0.4645, 0.9503, 0.2564, 0.6645, 0.8609, 0.3538,\n",
            "        0.3347])\n"
          ]
        }
      ],
      "source": [
        "word_embedding = torch.rand((d_model))\n",
        "print(\"word embedding for w in position 3\", word_embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCQVM1KH8ZcY"
      },
      "source": [
        "We simply sum these two vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OAi7pTL8ZcZ",
        "outputId": "df3259b3-a59e-4209-aad3-cfa925f5bcff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding vector and positional encoding added:  tensor([1.2012, 0.9851, 0.4523, 1.4643, 0.9516, 1.2564, 0.6646, 1.8609, 0.3538,\n",
            "        1.3347])\n"
          ]
        }
      ],
      "source": [
        "added = pe[2,:] + word_embedding\n",
        "print(\"Embedding vector and positional encoding added: \", added)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfBqkGya8ZcZ"
      },
      "source": [
        "\n",
        "Furthermore, we apply dropout on top of the sums of token embeddings and positional encodings. \n",
        "\n",
        "Build a function for positional encodings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FdWx4G7u8Zca"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"Implement the PE function.\"\n",
        "    def __init__(self, d_model, dropout, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "        # Compute the positional encodings once in log space.\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
        "                             -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x + Variable(self.pe[:, :x.size(1)], \n",
        "                         requires_grad=False)\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn18XqYtJDQv"
      },
      "source": [
        "Let's plot the 4th, 5th, 6th, 7th positional dimension of 100 tokens, each with embedding size of 20."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "YOT6D3ya8Zca",
        "outputId": "aa523322-060f-4d3a-f1d6-1ba5b730222b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "pe = PositionalEncoding(20, 0)\n",
        "y = pe.forward(Variable(torch.zeros(1, 100, 20)))\n",
        "plt.plot(np.arange(100), y[0, :, 4:8].data.numpy())\n",
        "plt.legend([\"dim %d\"%p for p in [4,5,6,7]])\n",
        "None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-c00JZ_JybY"
      },
      "source": [
        "In this tutorial, we will use positional embeddings that are initialized randomly and learned from scratch (we won't use sinusoidal embeddings). To build such positional embeddings, we can resort to nn.Embedding layer in the following way:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QpRVO8-jKWxc"
      },
      "outputs": [],
      "source": [
        "positional_encoding = nn.Embedding(max_seq_len, d_model) # contains \"max_seq_len\" positional embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3sPHcpEKleq"
      },
      "source": [
        "Let's pick a positional encoding for third token in the input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bsjMB29Kuh9",
        "outputId": "04564caf-191b-4ff1-c265-a66b9a26dc30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positional encoding for w in position 3:  tensor([[ 0.1642,  0.3744,  0.3704,  0.7420,  1.3308, -0.4382, -1.6271,  0.8957,\n",
            "          2.3701,  1.3993]], grad_fn=<EmbeddingBackward>)\n"
          ]
        }
      ],
      "source": [
        "print(\"Positional encoding for w in position 3: \", positional_encoding(torch.tensor([2]))) # 0-indexed, so refers to third positional embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCggzmMr8Zcb"
      },
      "source": [
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1nis5Pu3GDOUU4608i1qAzs-tRjVSk18L)\n",
        "\n",
        "So far, we have seen how to compose the input to a transformer block, by summing the input token embeddings with their corresponding positional encodings. \n",
        "\n",
        "The inputs and output of the multi-headed self-attention module are connected by residual connectors and a layer normalization layer. The output of the multi-headed self-attention is then passed to a two-layered feed-forward network which has its inputs/outputs similarly connected in a residual fashion with layer normalization. The sublayer residual connectors with layer norm is expressed as:\n",
        "\n",
        "$X = LayerNorm(F_S(X)) + X$\n",
        "\n",
        "where $F_S$ is the sub-layer module which is either the multi-headed self-attention or the position-wise feed-forward layers.\n",
        "\n",
        "### Multi-Head Self-Attention\n",
        "\n",
        "The Transformer model leverages a multi-headed self-attention mechanism. The key idea behind the mechanism is to learn an alignment (similar to Bahdanau's concatenative/additive attention, which we saw in the last tutorial) in which each element in the sequence learns to gather from other tokens in the sequence. The operation for a single head is defined as:\n",
        "\n",
        "$A_i = Softmax(\\alpha Q_i K_i^T)V_i$\n",
        "\n",
        "![](https://nlp.seas.harvard.edu/images/the-annotated-transformer_33_0.png)\n",
        "\n",
        "Picture Courtesy: https://nlp.seas.harvard.edu/images/the-annotated-transformer_33_0.png\n",
        "\n",
        "\n",
        "where $Q_i = W_i^q X$, $K_i = W_i^k X$, $V_i^v = W_i^v X$ are linear transformations applied on the temporal dimension of the input sequence. $W_i^q \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$, $W_i^k \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$, $W_i^v \\in \\mathbb{R}^{d_{\\text{model}} \\times d_v}$ are the weight matrices (parameters) for the query, key and value projections and project the input $X$ to an output tensor of d dimensions. Let us denote the number of heads by $h$.\n",
        "\n",
        "$X$ is a matrix of size $\\mathbb{R}^N \\times \\mathbb{R}^{d_{model}}$, and $\\alpha$ is a scaling factor that is typically set to $\\frac{1}{\\sqrt{{d_{model}}}}$.  The outputs of heads $A_1$...$A_{h}$ are concatenated together and passed into a dense layer. The output $Y$ can thus be expressed as $Y$ $=$ $W^o \\in \\mathbb{R}^{hd_v \\times d_{\\text{model}}}$ \\[$A_1$ ...$A_{h}]$, where $W^o$ is an output linear projection. Note that the computation of A is typically done in a parallel fashion.\n",
        "\n",
        "![](https://nlp.seas.harvard.edu/images/the-annotated-transformer_38_0.png)\n",
        "\n",
        "Picture Courtesy: https://nlp.seas.harvard.edu/images/the-annotated-transformer_38_0.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6V5atDn8Zcc"
      },
      "source": [
        "Let's see some sample code for computing attention ($A_h$):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wenFLUiS8Zcc"
      },
      "outputs": [],
      "source": [
        "def attention(query, key, value, mask=None, dropout=None):\n",
        "    \"Compute 'Scaled Dot Product Attention'\"\n",
        "    d_k = query.size(-1)\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
        "             / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    p_attn = F.softmax(scores, dim = -1)\n",
        "    if dropout is not None:\n",
        "        p_attn = dropout(p_attn)\n",
        "    return torch.matmul(p_attn, value), p_attn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3rjGz6J8Zcd"
      },
      "source": [
        "Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this.\n",
        "As discussed before, parameter matrices for linear projection for query, key, value, concatenated multihead output include $W^q_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$, $W^k_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$, $W^v_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_v}$ and $W^o \\in \\mathbb{R}^{d_v \\times d_{\\text{model}}}$. In the work of Vaswani et al., they employ $h=8$ parallel attention layers, or heads. For each of these they use $d_k=d_v=d_{\\text{model}}/h=64$. \n",
        "\n",
        "A sample code for implementing multi-head attention include:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clones(module, N):\n",
        "    \"Produce N identical layers.\"\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
      ],
      "metadata": {
        "id": "W32nrQ3-dp4D"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DP3wpTBc8Zcd"
      },
      "outputs": [],
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "        \"Take in model size and number of heads.\"\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "\n",
        "        # We assume d_v always equals d_k\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
        "        self.attn = None\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        if mask is not None:\n",
        "            # Same mask applied to all h heads.\n",
        "            mask = mask.unsqueeze(1)\n",
        "        nbatches = query.size(0)\n",
        "        \n",
        "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
        "        query, key, value = \\\n",
        "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "             for l, x in zip(self.linears, (query, key, value))]\n",
        "        \n",
        "        # q, k, v: [batch_size, n_head, seq_len, d_k]\n",
        "        # 2) Apply attention on all the projected vectors in batch. \n",
        "        x, self.attn = attention(query, key, value, mask=mask, \n",
        "                                 dropout=self.dropout)\n",
        "        \n",
        "        # 3) \"Concat\" using a view and apply a final linear. \n",
        "        x = x.transpose(1, 2).contiguous() \\\n",
        "             .view(nbatches, -1, self.h * self.d_k)\n",
        "        return self.linears[-1](x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYPzfWgfahNF"
      },
      "source": [
        "### Position-wise feed-forward layers\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1nis5Pu3GDOUU4608i1qAzs-tRjVSk18L)\n",
        "\n",
        "The outputs of the self-attention module is then passed into a two-layered feed-forward network with ReLU activations. This feed-forward layer operates on each position independently hence the term position-wise. This is expressed as follows:\n",
        "\n",
        "$\\text{FFN}(X_A) = max(0, X_A W_1 + b_1) W_2 + b_2$\n",
        "\n",
        "### Putting it all together\n",
        "\n",
        "Each transformer block can be expressed as:\n",
        "\n",
        "$X_A = \\text{LayerNorm}(\\text{MultiheadSelfAttention}(X)) + X$\n",
        "\n",
        "$X_B = \\text{LayerNorm}(\\text{FFN}(X_A)) + X_A$\n",
        "\n",
        "where X is the input of the Transformer block and $X_B$ is the output of the Transformer block.\n",
        "\n",
        "### Transformers\n",
        "\n",
        "It is important to note the differences in the mode of usage of the Transformer block. Transformers can primarily be used in three ways, namely:\n",
        "- encoder-only (e.g., for classification), \n",
        "- decoder-only (e.g., for language modeling), \n",
        "- encoder-decoder (e.g., for machine translation, which is our focus)\n",
        "\n",
        "In encoder-decoder mode, there are usually multiple multi-headed self-attention modules, including a standard self-attention in both the encoder and the decoder, along with an encoder-decoder cross-attention that allows the decoder to utilize information from the encoder. This influences the design of the self-attention mechanism. In the encoder mode, there is no restriction or constraint that the self-attention mechanism has to be causal, i.e., dependent solely on the present and past tokens. In the encoder-decoder setting, the encoder and encoder-decoder cross attention can afford to be non-causal but the decoder self-attention must be causal. The ability to support causal auto-regressive decoding is required when designing efficient self-attention mechanisms since it can be a limiting factor in many applications.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmdvYlZT4fZS"
      },
      "source": [
        "## Transformer model - Implementation\n",
        "\n",
        "[nn.Transformer](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html) module implements the entire encoder-decoder Transformer model, excluding the input token embeddings, position encodings, source and target masks. This module takes in the following parameters:\n",
        "- **$d_{\\text{model}}$** – the number of expected features in the encoder/decoder inputs \n",
        "- **nhead** – the number of heads in the multiheadattention models (the term 'h' in theory)\n",
        "- **num_encoder_layers** - the number of sub-encoder-layers in the encoder\n",
        "- **num_decoder_layers** - the number of sub-decoder-layers in the decoder\n",
        "- **dim_feedforward** -  the dimension of the feedforward network model\n",
        "- **dropout** - the dropout value\n",
        "\n",
        "Let's understand `nn.Transformer` module by passing a sample batch.\n",
        "\n",
        "Let's first convert the src and target word indices to word embeddings:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkn5j2H5ZPdt",
        "outputId": "2280d14f-b09c-4be1-9bef-c49c280cc395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token_embedding_encoder =  Embedding(6469, 512)\n",
            "token_embedding_decoder =  Embedding(5893, 512)\n",
            "src shape =  torch.Size([25, 16])\n",
            "targ shape =  torch.Size([23, 16])\n",
            "src_token_embeddings shape =  torch.Size([25, 16, 512])\n",
            "targ_token_embeddings shape =  torch.Size([23, 16, 512])\n"
          ]
        }
      ],
      "source": [
        "# word embedding layers for encoder (src) and decoder (targ)\n",
        "token_embedding_encoder = nn.Embedding(num_embeddings=len(SRC.vocab), embedding_dim=512).to(device) # src vocab size x embedding size\n",
        "print(\"token_embedding_encoder = \", token_embedding_encoder)\n",
        "token_embedding_decoder = nn.Embedding(num_embeddings=len(TRG.vocab), embedding_dim=512).to(device) # targ vocab size x embedding size\n",
        "print(\"token_embedding_decoder = \", token_embedding_decoder)\n",
        "\n",
        "# print the shape tensors in sample batch: src and targ\n",
        "print(\"src shape = \", src.shape) # src. max. seq len x batch size\n",
        "print(\"targ shape = \", trg.shape) # targ. max. seq len x batch size\n",
        "\n",
        "# pass the word indices to embedding layer to get embeddings\n",
        "src_token_embeddings = token_embedding_encoder(src.to(device))\n",
        "print(\"src_token_embeddings shape = \", src_token_embeddings.shape) # src. max. seq len x batch size x embedding size\n",
        "targ_token_embeddings = token_embedding_decoder(trg.to(device))\n",
        "print(\"targ_token_embeddings shape = \", targ_token_embeddings.shape) # targ. max. seq len x batch size x embedding size\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-PQXPReav6B"
      },
      "source": [
        "Having built word embeddings, we can now build position embeddings for both encoder and decoder. Let's start by defining the position embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oG9wCQw7a9k1",
        "outputId": "5a2d2ffa-e937-421c-bf27-ce81db382050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "position_embedding_encoder =  Embedding(200, 512)\n",
            "position_embedding_decoder =  Embedding(200, 512)\n"
          ]
        }
      ],
      "source": [
        "# position embedding layers for encoder (src) and decoder (targ)\n",
        "maximum_sentence_len = 200 # this will be the maximum length of source and target sentence that our model can process (can have separate maximum lengths for both encoder and decoder)\n",
        "position_embedding_encoder = nn.Embedding(num_embeddings=maximum_sentence_len, embedding_dim=512).to(device) # maximum_sentence_len x embedding size\n",
        "print(\"position_embedding_encoder = \", position_embedding_encoder)\n",
        "position_embedding_decoder = nn.Embedding(num_embeddings=maximum_sentence_len, embedding_dim=512).to(device) # maximum_sentence_len x embedding size\n",
        "print(\"position_embedding_decoder = \", position_embedding_decoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFeSYt3vb95Y"
      },
      "source": [
        "Now we can create the positional input for both encoder and decoder. For a single example setting, the positional inputs can be created as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWXDi_Khcso6",
        "outputId": "322c83ed-fedb-4cb4-e6a5-2032d8322d3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positional input for a single source example =  tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22, 23, 24]) torch.Size([25])\n",
            "positional input for a single target example =  tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19, 20, 21, 22]) torch.Size([23])\n"
          ]
        }
      ],
      "source": [
        "# if the no. of tokens in the source sentence is `src_seq_len`\n",
        "src_seq_len = src.size(0)\n",
        "src_position = torch.arange(0, src_seq_len)\n",
        "print('positional input for a single source example = ', src_position, src_position.shape)\n",
        "\n",
        "# if the no. of tokens in the target sentence is `trg_seq_len`\n",
        "trg_seq_len = trg.size(0)\n",
        "trg_position = torch.arange(0, trg_seq_len)\n",
        "print('positional input for a single target example = ', trg_position, trg_position.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3ymxRBUdVbF"
      },
      "source": [
        "If we have a batch of examples, the positional inputs can be extended to batch as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUSR0Vzld9gQ",
        "outputId": "c2b6b49c-7292-45d3-d4ae-d80a60ce5b04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positional input for a source batch =  tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
            "        [ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3],\n",
            "        [ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4],\n",
            "        [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
            "        [ 6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6],\n",
            "        [ 7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
            "        [ 8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8],\n",
            "        [ 9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9],\n",
            "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
            "        [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11],\n",
            "        [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n",
            "        [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13],\n",
            "        [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
            "        [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
            "        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "        [17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
            "        [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
            "        [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19],\n",
            "        [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
            "        [21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21],\n",
            "        [22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22],\n",
            "        [23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23],\n",
            "        [24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24]],\n",
            "       device='cuda:0') torch.Size([25, 16])\n"
          ]
        }
      ],
      "source": [
        "batch_size = src.size(1) # size of the current batch\n",
        "src_position = (torch.arange(0, src_seq_len).unsqueeze(1).expand(src_seq_len, batch_size).to(device))\n",
        "print('positional input for a source batch = ', src_position, src_position.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn33_TdQeW1d"
      },
      "source": [
        "Similarly for the target batch,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BHjO8lfebzF",
        "outputId": "33e37b40-a0c2-4304-ad73-e4f0bda7c3a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positional input for a target batch =  tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
            "        [ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3],\n",
            "        [ 4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4],\n",
            "        [ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
            "        [ 6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6],\n",
            "        [ 7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7],\n",
            "        [ 8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8],\n",
            "        [ 9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9],\n",
            "        [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
            "        [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11],\n",
            "        [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n",
            "        [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13],\n",
            "        [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
            "        [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
            "        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
            "        [17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
            "        [18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18],\n",
            "        [19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19],\n",
            "        [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
            "        [21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21],\n",
            "        [22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22]],\n",
            "       device='cuda:0') torch.Size([23, 16])\n"
          ]
        }
      ],
      "source": [
        "batch_size = trg.size(1) # size of the current batch\n",
        "targ_position = (torch.arange(0, trg_seq_len).unsqueeze(1).expand(trg_seq_len, batch_size).to(device))\n",
        "print('positional input for a target batch = ', targ_position, targ_position.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l638opIefT9_"
      },
      "source": [
        "The positional embeddings can be obtained by passing the position input to position embeddings layer of encoder and decoder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U-EFvc9f4pt",
        "outputId": "29e7c008-a087-4cda-bdd6-fa70580cfd13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positional input for source =  torch.Size([25, 16])\n",
            "positional embeddings for source =  torch.Size([25, 16, 512])\n",
            "positional input for target =  torch.Size([23, 16])\n",
            "positional embeddings for target =  torch.Size([23, 16, 512])\n"
          ]
        }
      ],
      "source": [
        "src_pos_embeddings = position_embedding_encoder(src_position)\n",
        "print('positional input for source = ', src_position.shape)\n",
        "print('positional embeddings for source = ', src_pos_embeddings.shape)\n",
        "\n",
        "targ_pos_embeddings = position_embedding_encoder(targ_position)\n",
        "print('positional input for target = ', targ_position.shape)\n",
        "print('positional embeddings for target = ', targ_pos_embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "183LmdZNever"
      },
      "source": [
        "Having built word embedding and position embedding, we can now add both the embeddings to create the input embedding to Transformer module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sYHC_Ype4Uy",
        "outputId": "154c0c92-f09f-4af2-ff4b-6b724da5862f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input embedding for source =  torch.Size([25, 16, 512])\n",
            "input embedding for target =  torch.Size([23, 16, 512])\n"
          ]
        }
      ],
      "source": [
        "src_input_embedding = src_token_embeddings + src_pos_embeddings\n",
        "print('input embedding for source = ', src_input_embedding.shape)\n",
        "targ_input_embedding = targ_token_embeddings + targ_pos_embeddings\n",
        "print('input embedding for target = ', targ_input_embedding.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGWNRwvKh5kx"
      },
      "source": [
        "We can optionally add dropout to both the input embeddings before feeding as an input to Transformer.\n",
        "\n",
        "Similar to our last week's tutorial, we need to create a binary mask for the source tokens that marks the pad tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVpy0OHPihch",
        "outputId": "992154be-b45f-4d42-b963-0d7d3aef5a71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[False, False, False, False, False, False, False, False, False,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "          True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False,  True,  True,\n",
            "          True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False, False, False,  True,  True,\n",
            "          True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# create the source (pad) mask\n",
        "mask_src = (src == SRC.vocab.stoi[SRC.pad_token]).transpose(0, 1).to(device) # batch size x src max. seq length\n",
        "print(mask_src)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmjynIoDj0nG"
      },
      "source": [
        "We can now create an instance from `nn.Transformer` module:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhGWDYg2kMnu",
        "outputId": "b55dfd31-2737-4683-d077-1879102fc47d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (multihead_attn): MultiheadAttention(\n",
            "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        (dropout3): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (multihead_attn): MultiheadAttention(\n",
            "          (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "        (dropout3): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# check doc for details about the input arguments\n",
        "# https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
        "embed_dim = 512 #  the number of expected features in the encoder/decoder inputs\n",
        "nhead = 8 # the number of heads in the multiheadattention models\n",
        "num_encoder_layers = 2 # the number of sub-encoder-layers in the encoder\n",
        "num_decoder_layers = 2 # the number of sub-decoder-layers in the decoder\n",
        "dim_feedforward = 1024 # the dimension of the feedforward network model\n",
        "dropout = 0.1 # the dropout value (default=0.1)\n",
        "transformer_layer = nn.Transformer(d_model=embed_dim, nhead=nhead, num_encoder_layers=num_encoder_layers, dropout=dropout, num_decoder_layers=num_decoder_layers, dim_feedforward=dim_feedforward).to(device)\n",
        "print(transformer_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLW-JdWmjSXe"
      },
      "source": [
        "We have created all the inputs that we need to pass to Transformer module except one: **target mask** that makes the decoder attend to only the past decoder context while predicting the next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af2LisC3jRuo",
        "outputId": "85203539-8989-4f21-e9f5-de43e56ed63d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mask target =  tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "       device='cuda:0') torch.Size([23, 23])\n"
          ]
        }
      ],
      "source": [
        "# create the target (self-attention) mask \n",
        "targ_seq_len = trg.size(0)\n",
        "mask_targ = transformer_layer.generate_square_subsequent_mask(targ_seq_len).to(device)\n",
        "print(\"mask target = \", mask_targ, mask_targ.shape)  # targ. seq len x targ. seq len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqZzGkufqf9q"
      },
      "source": [
        "Let's now pass all the tensor we've created to transformer layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38ivfxVuqjlX",
        "outputId": "528ccb38-b87d-4e94-de26-857f991035e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of src_input_embedding =  torch.Size([25, 16, 512])\n",
            "shape of targ_input_embedding =  torch.Size([23, 16, 512])\n",
            "shape of mask_src =  torch.Size([16, 25])\n",
            "shape of mask_targ =  torch.Size([23, 23])\n",
            "shape of the transformer output =  torch.Size([23, 16, 512])\n"
          ]
        }
      ],
      "source": [
        "print(\"shape of src_input_embedding = \", src_input_embedding.shape) # src. seq len x batch size x embedding size \n",
        "print(\"shape of targ_input_embedding = \", targ_input_embedding.shape)  # targ. seq len x batch size x embedding size \n",
        "print(\"shape of mask_src = \", mask_src.shape) #  batch size x src. seq len\n",
        "print(\"shape of mask_targ = \", mask_targ.shape) # targ. seq len x targ. seq len\n",
        "output = transformer_layer(src_input_embedding, targ_input_embedding, src_key_padding_mask=mask_src, tgt_mask=mask_targ)\n",
        "print(\"shape of the transformer output = \", output.shape) # targ. seq len x batch size x embedding size "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qzsqImyYvd4"
      },
      "source": [
        "Having seen an example for using Transformer module, let's implement the Transformer model for machine translation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "lzTQKNQ9d6gw"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab, trg_vocab, embed_dim, nhead, num_encoder_layers, dropout, num_decoder_layers, dim_feedforward, maximum_sentence_len=200):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        # get initial hyper-parameters\n",
        "        self.src_vocab = src_vocab\n",
        "        self.trg_vocab = trg_vocab\n",
        "        self.embed_dim = embed_dim\n",
        "        self.nhead = nhead\n",
        "        self.num_encoder_layers = num_encoder_layers\n",
        "        self.dropout = dropout\n",
        "        self.num_decoder_layers = num_decoder_layers\n",
        "        self.dim_feedforward = dim_feedforward\n",
        "\n",
        "        # add embedding layers\n",
        "        self.token_embedding_encoder = nn.Embedding(num_embeddings=self.src_vocab, embedding_dim=self.embed_dim)\n",
        "        self.token_embedding_decoder = nn.Embedding(num_embeddings=self.trg_vocab, embedding_dim=self.embed_dim)\n",
        "        self.position_embedding_encoder = nn.Embedding(num_embeddings=maximum_sentence_len, embedding_dim=self.embed_dim)\n",
        "        self.position_embedding_decoder = nn.Embedding(num_embeddings=maximum_sentence_len, embedding_dim=self.embed_dim)\n",
        "\n",
        "        # Encoder-Decoder Transformer\n",
        "        self.transformer = nn.Transformer(d_model=self.embed_dim, nhead=self.nhead, num_encoder_layers=self.num_encoder_layers, dropout=self.dropout, num_decoder_layers=self.num_decoder_layers, dim_feedforward=self.dim_feedforward)\n",
        "\n",
        "        # output layer to predict next token\n",
        "        self.decoder = nn.Linear(self.embed_dim, self.trg_vocab)\n",
        "        self.drop_layer = nn.Dropout()\n",
        "\n",
        "    def forward(self, src, tgr):\n",
        "        # read shapes\n",
        "        # src = src_seq_len x batch_size\n",
        "        # tgr = targ_seq_len x batch_size\n",
        "        src_seq_len, batch_size = src.shape\n",
        "        targ_seq_len, _ = tgr.shape\n",
        "\n",
        "        # create position input for encoder\n",
        "        src_position = (torch.arange(0, src_seq_len).unsqueeze(1).expand(src_seq_len, batch_size).to(device))\n",
        "        # src_position = src_seq_len x batch_size\n",
        "\n",
        "        # create position input for decoder\n",
        "        targ_position = (torch.arange(0, targ_seq_len).unsqueeze(1).expand(targ_seq_len, batch_size).to(device))\n",
        "        # src_position = targ_seq_len x batch_size\n",
        "\n",
        "        # input embedding by merging token embedding with position embedding\n",
        "        embed_src = self.drop_layer((self.token_embedding_encoder(src) + self.position_embedding_encoder(src_position)))\n",
        "        embed_tgr = self.drop_layer((self.token_embedding_decoder(tgr) + self.position_embedding_decoder(targ_position)))\n",
        "        # embed_src = src_seq_len x batch_size x d_model\n",
        "        # embed_src = targ_seq_len x batch_size x d_model\n",
        "\n",
        "        # create mask for source\n",
        "        mask_src = (src == SRC.vocab.stoi[SRC.pad_token]).transpose(0, 1).to(device)\n",
        "        # mask_src = batch_size x src_seq_len\n",
        "\n",
        "        # create mask for target\n",
        "        mask_targ = self.transformer.generate_square_subsequent_mask(targ_seq_len).to(device)\n",
        "        # mask_targ = targ_seq_len x targ_seq_len\n",
        "\n",
        "        # feed via transformer\n",
        "        output = self.transformer(embed_src, embed_tgr, src_key_padding_mask=mask_src, tgt_mask=mask_targ)\n",
        "        # output = targ_seq_len x batch_size x d_model\n",
        "\n",
        "        # transform the output to match no of. tokens in target vocab \n",
        "        output = self.decoder(output) \n",
        "        # output = targ_seq_len x batch_size x targ_vocab_size\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoS8rucEedqT"
      },
      "source": [
        "Let's set the hyperparameters and create a model instance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "7WodGURxfLeW"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "src_vocab = len(SRC.vocab)\n",
        "trg_vocab = len(TRG.vocab)\n",
        "embed_dim = 512\n",
        "nhead = 4\n",
        "num_encoder_layers = 2\n",
        "dropout = 0.1 \n",
        "num_decoder_layers = 2\n",
        "dim_feedforward = 512\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# model instance\n",
        "model = Transformer(src_vocab, trg_vocab, embed_dim, nhead, num_encoder_layers, dropout, num_decoder_layers, dim_feedforward).to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtQFCFbOfSi6"
      },
      "source": [
        "Let's define the train logic (for a single epoch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "PViJMT42fd13"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    manual_seed = 77\n",
        "    torch.manual_seed(manual_seed)\n",
        "    if n_gpu > 0:\n",
        "        torch.cuda.manual_seed(manual_seed)\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.SRC.to(device)\n",
        "        trg = batch.TRG.to(device)\n",
        "        # src = src seq len x batch size\n",
        "        # trg = targ seq len x batch size\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg[:-1, :]) # for target, provide targ seq len-1 tokens for each sentence\n",
        "        \n",
        "        #output = [targ seq len-1, batch size, output dim]\n",
        "\n",
        "        output = output.reshape(-1, output.shape[2])\n",
        "        target = trg[1:].reshape(-1)\n",
        "\n",
        "        # loss function works only 2d logits, 1d targets\n",
        "        # so flatten the trg, output tensors. Ignore the <sos> token\n",
        "        # target shape shape should be [(targ seq len - 1) * batch_size]\n",
        "        # output shape should be [(targ seq len - 1) * batch_size, output_dim]\n",
        "        loss = criterion(output, target)\n",
        "        \n",
        "        loss.backward()\n",
        "\n",
        "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
        "        # within a healthy range\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru4U9cK4fo6B"
      },
      "source": [
        "Let's define the inference logic for evaluating the quality of the model based on BLEU score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "BMTmcVhefrWH"
      },
      "outputs": [],
      "source": [
        "def inference(model, file_name, src_vocab, trg_vocab, attention = False, max_trg_len = 64):\n",
        "    '''\n",
        "    Function for translation inference\n",
        "\n",
        "    Input: \n",
        "    model: translation model;\n",
        "    file_name: the directoy of test file that the first column is target reference, and the second column is source language;\n",
        "    trg_vocab: Target torchtext Field\n",
        "    attention: the model returns attention weights or not.\n",
        "    max_trg_len: the maximal length of translation text (optinal), default = 64\n",
        "\n",
        "    Output:\n",
        "    Corpus BLEU score.\n",
        "    '''\n",
        "    from nltk.translate.bleu_score import corpus_bleu\n",
        "    from nltk.translate.bleu_score import sentence_bleu\n",
        "    from torchtext.data import TabularDataset\n",
        "    from torchtext.data import Iterator\n",
        "\n",
        "    # convert index to text string\n",
        "    def convert_itos(convert_vocab, token_ids):\n",
        "        list_string = []\n",
        "        for i in token_ids:\n",
        "            if i == convert_vocab.vocab.stoi['<eos>']:\n",
        "                break\n",
        "            else:\n",
        "                token = convert_vocab.vocab.itos[i]\n",
        "                list_string.append(token)\n",
        "        return list_string\n",
        "\n",
        "    test = TabularDataset(\n",
        "      path=file_name, # the root directory where the data lies\n",
        "      format='tsv',\n",
        "      skip_header=True, # if your tsv file has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
        "      fields=[('TRG', trg_vocab), ('SRC', src_vocab)])\n",
        "\n",
        "    test_iter = Iterator(\n",
        "      dataset = test, # we pass in the datasets we want the iterator to draw data from\n",
        "      sort = False, \n",
        "      batch_size=1,\n",
        "      sort_key=None,\n",
        "      shuffle=False,\n",
        "      sort_within_batch=False,\n",
        "      device = device,\n",
        "      train=False\n",
        "    )\n",
        "  \n",
        "    model.eval()\n",
        "    all_gold_trg_tokids = []\n",
        "    all_translated_trg_tokids = []\n",
        "\n",
        "    TRG_PAD_IDX = trg_vocab.vocab.stoi[trg_vocab.pad_token]\n",
        "\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(test_iter):\n",
        "\n",
        "            src = batch.SRC.to(device)\n",
        "            #src = [src len, batch size]\n",
        "\n",
        "            trg = batch.TRG.to(device)\n",
        "\n",
        "            #src = GOLD_SRC.to(device)\n",
        "            #trg = GOLD_TRG.to(device)\n",
        "            #trg = [trg len, batch size]\n",
        "\n",
        "            batch_size = trg.shape[1]\n",
        "\n",
        "            outputs = [trg_vocab.vocab.stoi[\"<sos>\"]]\n",
        "            for i in range(max_trg_len):\n",
        "                trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
        "                \n",
        "                output = model(src, trg_tensor)\n",
        "\n",
        "                topv, topi = output[-1,0,:].topk(1)\n",
        "                cur_decoded_token = topi.squeeze().detach()  # detach from history as input\n",
        "                outputs.append(cur_decoded_token.item())\n",
        "\n",
        "                if cur_decoded_token.item() == trg_vocab.vocab.stoi[\"<eos>\"]:\n",
        "                    break\n",
        "            all_translated_trg_tokids.append(outputs[1:-1])\n",
        "            all_gold_trg_tokids.append([ trg[idx, 0].item() for idx in range(1, trg.size(0)-1)])\n",
        "    \n",
        "    # convert token ids to token strs\n",
        "    all_gold_text = []\n",
        "    all_translated_text = []\n",
        "    for i in range(len(all_gold_trg_tokids)): \n",
        "        all_gold_text.append([[trg_vocab.vocab.itos[idx] for idx in all_gold_trg_tokids[i]]])\n",
        "        all_translated_text.append([trg_vocab.vocab.itos[idx] for idx in all_translated_trg_tokids[i]])\n",
        "        \n",
        "    corpus_bleu_score = corpus_bleu(all_gold_text, all_translated_text)  \n",
        "    return corpus_bleu_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKl8mukAgC2g"
      },
      "source": [
        "Let's define the evaluation logic to compute the quality of the model based on the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "XXny41OTgSvR"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.SRC.to(device)\n",
        "            trg = batch.TRG.to(device)\n",
        "\n",
        "            output = model(src, trg[:-1, :]) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            #output = output[1:].view(-1, output_dim)\n",
        "            #trg = trg[1:].view(-1)\n",
        "\n",
        "            output = output.reshape(-1, output.shape[2])\n",
        "            target = trg[1:].reshape(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            #break\n",
        "        \n",
        "    bleu = inference(model, \"./drive/MyDrive/Colab_Notebooks/eng-fre/val_eng_fre.tsv\", SRC, TRG, False, 64)\n",
        "    return epoch_loss / len(iterator) , bleu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3dXPDyxglqh"
      },
      "source": [
        "Let's perform the full-training of the Transformer model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSpD9QFZgp4Q"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "# set the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# create the loss function\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "print('<pad> token index: ', TRG_PAD_IDX)\n",
        "## we will ignore the pad token in true target set\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
        "\n",
        "# numer of epochs (hyperparameter)\n",
        "N_EPOCHS = 15\n",
        "\n",
        "# initial best valid loss\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# kick-start training\n",
        "print('Training started...')\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iter, optimizer, criterion)\n",
        "    valid_loss, bleu = evaluate(model, val_iter, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    # Create checkpoint at end of each epoch\n",
        "    state_dict_model = model.state_dict() \n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'state_dict': state_dict_model,\n",
        "        'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "\n",
        "    torch.save(state, \"./drive/MyDrive/Colab_Notebooks/ckpt_attn/seq2seq_\"+str(epoch+1)+\".pt\")\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\t Train Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "    print(f'\\t Val. BLEU: {bleu:7.3f}')\n",
        "\n",
        "# Evaluate the model after the last epoch on the test set\n",
        "test_loss, bleu_test = evaluate(model, test_iter, criterion)\n",
        "print(f'\\t Test BLEU: {bleu_test:7.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkhxPPcxhaMO"
      },
      "source": [
        "## Reference:\n",
        "\n",
        "https://nlp.seas.harvard.edu/2018/04/03/attention.html#position-wise-feed-forward-networks\n",
        "\n",
        "https://pytorch.org/docs/master/nn.html#transformerencoderlayer\n",
        "\n",
        "https://pytorch.org/docs/master/_modules/torch/nn/modules/transformer.html#Transformer"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}